{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNET pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqyHRTL9YL57Crs1YHqfog",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tohkunhao/Paper-Implementation/blob/main/EfficientNET_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi8e4QQWJcPF"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EfficientNET(nn.Module):\n",
        "    '''\n",
        "    Based on the paper by （以下の論文の実装です。）\n",
        "    Mingxing Tan, Quoc V. Le\n",
        "    EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n",
        "    ICML'19, https://arxiv.org/abs/1905.11946\n",
        "    \n",
        "    Resolution for each of the scaled model is as follows.\n",
        "    B0～B7の解像度は次です。\n",
        "    B0:224, B1:240, B2:260, B3:300, B4:380, B5:456, B6:528, B7:600\n",
        "    \n",
        "    Takes in arguments input channels, num_classes, optional (B0~B7 variant), optional batchnorm momentum, optional batchnorm epsilon\n",
        "    入力は入力画像のチャンネル数、分類クラス数、（任意）B0~B7の種類、（任意）バッチ正規化のモメンタム、（任意）バッチ正規化の0除算防ぎ小数\n",
        "    \n",
        "    '''\n",
        "    def __init__(self,in_channels,num_classes,architecture='B0',BN_momentum = 0.99,BN_eps =1e-3):\n",
        "        super(EfficientNET,self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.channelscale = {'B0':1,'B1':1,'B2':1.1,'B3':1.2,'B4':1.4,'B5':1.6,'B6':1.8,'B7':2}\n",
        "        self.depthscale = {'B0':1,'B1':1.1,'B2':1.2,'B3':1.4,'B4':1.8,'B5':2.2,'B6':2.6,'B7':3.1}\n",
        "        self.BN_momentum = BN_momentum\n",
        "        self.BN_eps = BN_eps\n",
        "        self.survival_prob = 0.8\n",
        "        self.dropoutparams = [0.2,0.2,0.3,0.3,0.4,0.4,0.5,0.5] \n",
        "        self.dropout = self.dropoutparams[int(architecture[1])]\n",
        "        \n",
        "        #architecture follows the format: conv type, num filters(out channels), num layers, kernel size, stride, padding\n",
        "        self.architecture = [['C',32,1,3,2,1],\n",
        "                            ['MB1',self.channelscaling(self.channelscale[architecture],16),self.depthscaling(self.depthscale[architecture],1),3,1,1],\n",
        "                            ['MB6',self.channelscaling(self.channelscale[architecture],24),self.depthscaling(self.depthscale[architecture],2),3,2,1],\n",
        "                            ['MB6',self.channelscaling(self.channelscale[architecture],40),self.depthscaling(self.depthscale[architecture],2),5,2,2],\n",
        "                            ['MB6',self.channelscaling(self.channelscale[architecture],80),self.depthscaling(self.depthscale[architecture],3),3,2,1],\n",
        "                            ['MB6',self.channelscaling(self.channelscale[architecture],112),self.depthscaling(self.depthscale[architecture],3),5,1,2],\n",
        "                            ['MB6',self.channelscaling(self.channelscale[architecture],192),self.depthscaling(self.depthscale[architecture],4),5,2,2],\n",
        "                            ['MB6',self.channelscaling(self.channelscale[architecture],320),self.depthscaling(self.depthscale[architecture],1),3,1,1],\n",
        "                            ['C',1280,1,1,1,0]]\n",
        "        \n",
        "        self.EffNet = nn.Sequential(self.create_layers(),nn.AdaptiveAvgPool2d(1),nn.Flatten(),nn.Dropout(self.dropout),nn.Linear(1280,num_classes)).apply(self.init_weights)\n",
        "    \n",
        "    def create_layers(self): #return list of layers (nn要素のリストを返す)\n",
        "        in_channels=self.in_channels\n",
        "        layers=[]\n",
        "        for stage in self.architecture:\n",
        "            if stage[0]=='C': #regular convolution (普通の畳み込み)\n",
        "                layers.append(nn.Conv2d(in_channels,stage[1],stage[3],stride=stage[4],padding=stage[5]))\n",
        "                in_channels = stage[1] #in channels = out channels\n",
        "                layers.append(nn.BatchNorm2d(in_channels,momentum = self.BN_momentum,eps = self.BN_eps)) #momentum value as stated in paper\n",
        "                layers.append(nn.SiLU())\n",
        "            \n",
        "            else:#execute MBConv (MobileNetV2の畳み込み)\n",
        "                for layer_num in range(stage[2]):\n",
        "                    layers.append(MBConv(in_channels,stage,layer_num,self.survival_prob,self.BN_momentum,self.BN_eps))\n",
        "                    in_channels = stage[1]\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        return self.EffNet(x)\n",
        "    \n",
        "    #function to scale channels for B0~B7\n",
        "    def channelscaling(self,scale,channels):\n",
        "        channels = channels*scale\n",
        "        new_channels = max(8,int(channels+4)//8*8) #8の倍率にするため\n",
        "        if new_channels <0.9 * channels:\n",
        "            new_channels += 8\n",
        "        return int(new_channels)\n",
        "    \n",
        "    #function to scale layers for B0~B7\n",
        "    def depthscaling(self,scale,layers):\n",
        "        return int(math.ceil(scale*layers))\n",
        "    \n",
        "    #initialize weights\n",
        "    def init_weights(self,m):\n",
        "        if type(m) == nn.Linear:\n",
        "            nn.init.kaiming_uniform_(m.weight,a=np.sqrt(5),mode='fan_out',nonlinearity='leaky_relu')\n",
        "        elif type(m) == nn.Conv2d:\n",
        "            nn.init.kaiming_normal_(m.weight,mode = 'fan_out',nonlinearity = 'relu')\n",
        "    \n",
        "class MBConv(nn.Module):#mobile inverted bottleneck\n",
        "    '''\n",
        "    以下の論文を参照しました。\n",
        "    Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, Quoc V. Le\n",
        "    MnasNet: Platform-Aware Neural Architecture Search for Mobile\n",
        "    arXiv:1807.11626v3\n",
        "    \n",
        "    Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen\n",
        "    MobileNetV2: Inverted Residuals and Linear Bottlenecks\n",
        "    arXiv:1801.04381v4\n",
        "    '''\n",
        "    def __init__(self,in_channels,stage_archi_list,layer_num,survival_probability,BN_momentum, BN_eps):\n",
        "        super(MBConv,self).__init__()\n",
        "        if stage_archi_list[0] == 'MB1':#拡大係数は1\n",
        "            self.expansion = 1\n",
        "        else:#拡大係数は6\n",
        "            self.expansion = 6\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = stage_archi_list[1]\n",
        "        self.layers = layer_num\n",
        "        self.kernel_size = stage_archi_list[3]\n",
        "        self.layer1stride = stage_archi_list[4]\n",
        "        self.padding = stage_archi_list[5]\n",
        "        self.BN_momentum = BN_momentum\n",
        "        self.BNeps = BN_eps\n",
        "        self.survival_prob = survival_probability\n",
        "        self.mbconv = self.MBConvblock(self.in_channels,self.layers)\n",
        "    \n",
        "    def conv1x1block(self,in_channels,activation='SiLU',order = 'first'):\n",
        "        layers=[]\n",
        "        if order == 'first':\n",
        "            out_channels = in_channels * self.expansion\n",
        "        elif order == 'last':\n",
        "            out_channels = self.out_channels\n",
        "        layers.append(nn.Conv2d(in_channels,out_channels,kernel_size=1))\n",
        "        layers.append(nn.BatchNorm2d(out_channels,momentum = self.BN_momentum,eps = self.BNeps))\n",
        "        if activation == 'SiLU':\n",
        "            layers.append(nn.SiLU())\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def depthwiseblock(self,in_channels,layer_num):\n",
        "        layers=[]\n",
        "        if layer_num == 0:\n",
        "            stride = self.layer1stride\n",
        "        else:\n",
        "            stride = 1\n",
        "        layers.append(nn.Conv2d(in_channels,in_channels,kernel_size = self.kernel_size,stride = stride,padding = self.padding,groups = in_channels)) #group makes it depthwise\n",
        "        layers.append(nn.BatchNorm2d(in_channels,momentum = self.BN_momentum,eps = self.BNeps))\n",
        "        layers.append(nn.SiLU())\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def MBConvblock(self,in_channels,layer_num):\n",
        "        return nn.Sequential(self.conv1x1block(in_channels),self.depthwiseblock(in_channels*self.expansion,layer_num),SEBlock(in_channels*self.expansion),self.conv1x1block(in_channels*self.expansion,activation = None,order = 'last'))\n",
        "      \n",
        "    def StochasticDepth(self,x):\n",
        "        if not self.training:\n",
        "            return x\n",
        "        prob = torch.rand((x.shape[0],1,1,1)).to('cuda' if torch.cuda.is_available else 'cpu')\n",
        "        mask = prob < self.survival_prob\n",
        "        return torch.mul(torch.div(x,self.survival_prob),mask)\n",
        "      \n",
        "    def forward(self,x):\n",
        "        if self.layers == 0: #first layer in the layers\n",
        "            return self.mbconv(x)\n",
        "        else:\n",
        "            return torch.add(self.StochasticDepth(self.mbconv(x)),x)#画像解像度を半分にする層以外Stochastic Depthを実施する\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    '''\n",
        "    以下の論文を参照しました。\n",
        "    Jie Hu, Li Shen, Samuel Albanie, Gang Sun, Enhua Wu\n",
        "    Squeeze-and-Excitation Networks\n",
        "    arXiv:1709.01507v4\n",
        "    '''\n",
        "    def __init__(self,in_channels):\n",
        "        super(SEBlock,self).__init__()\n",
        "        self.SEratio = 0.25\n",
        "        self.in_channels = in_channels\n",
        "        self.squeezedchannels = max(1,int(0.25*in_channels)) #チャンネル数は4分の1まで圧縮する\n",
        "        self.squeezeexcite = self.SE()\n",
        "    \n",
        "    def SE(self):#squeeze and excitation\n",
        "        return nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
        "                             nn.Conv2d(self.in_channels,self.squeezedchannels,kernel_size=1,bias=False),\n",
        "                            nn.SiLU(),\n",
        "                            nn.Conv2d(self.squeezedchannels,self.in_channels,kernel_size=1,bias=False),\n",
        "                            nn.Sigmoid())\n",
        "    \n",
        "    def forward(self,x):\n",
        "        return torch.mul(self.squeezeexcite(x),x)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}